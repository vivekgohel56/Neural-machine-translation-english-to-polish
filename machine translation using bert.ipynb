{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"machine translation using bert.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1RjveW9xl-yc82b87G6R3ZCwteYlUg8yY","authorship_tag":"ABX9TyNsxi0RBik9zQSYk8/5p3Hr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"wLxBQJ8z0rUd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":722},"executionInfo":{"status":"ok","timestamp":1600318128418,"user_tz":-330,"elapsed":14422,"user":{"displayName":"vivek gohel","photoUrl":"","userId":"08799214395694087015"}},"outputId":"0457a63c-5f20-472d-c683-825e83de7ac9"},"source":["!pip install tensorflow-datasets\n","!pip install bert-for-tf2\n","\n","from __future__ import absolute_import, division, print_function, unicode_literals\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","import tensorflow_hub as hub\n","\n","import string\n","from string import digits\n","import re\n","import time\n","import numpy as np\n","import pandas as pd\n","import collections\n","import unicodedata\n","\n","import os\n","\n","from bert import BertModelLayer\n","from bert.loader import StockBertConfig, load_stock_weights"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.6/dist-packages (2.1.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (1.12.1)\n","Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (2.3)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (0.24.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (1.18.5)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (0.10.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (0.3.2)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (0.16.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (3.12.4)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (1.1.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (4.41.1)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (20.2.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (1.15.0)\n","Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets) (1.52.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-datasets) (50.3.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2.10)\n","Collecting bert-for-tf2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/c1/015648a2186b25c6de79d15bec40d3d946fcf1dd5067d1c1b28009506486/bert-for-tf2-0.14.6.tar.gz (40kB)\n","\u001b[K     |████████████████████████████████| 40kB 2.4MB/s \n","\u001b[?25hCollecting py-params>=0.9.6\n","  Downloading https://files.pythonhosted.org/packages/a4/bf/c1c70d5315a8677310ea10a41cfc41c5970d9b37c31f9c90d4ab98021fd1/py-params-0.9.7.tar.gz\n","Collecting params-flow>=0.8.0\n","  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n","Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n","  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.6-cp36-none-any.whl size=30318 sha256=7c2085c9eda2f39aede11ba813b381245dac00a4d8ee1f6c2315974f154579e1\n","  Stored in directory: /root/.cache/pip/wheels/07/a0/b4/75b0601ebaa41e517a797fe9cea119c789664c8408f8a74ae9\n","  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-params: filename=py_params-0.9.7-cp36-none-any.whl size=7304 sha256=b4f9636c4fbf2aae8428784997b6b04d2f0beddbfe0d2c3325d2314d6251a07a\n","  Stored in directory: /root/.cache/pip/wheels/67/f5/19/b461849a50aefdf4bab47c4756596e82ee2118b8278e5a1980\n","  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for params-flow: filename=params_flow-0.8.2-cp36-none-any.whl size=19475 sha256=0396865df790a2bdf9bb31ccf2b0a0c0a763ce565e90d575d14026c2dc5493b3\n","  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n","Successfully built bert-for-tf2 py-params params-flow\n","Installing collected packages: py-params, params-flow, bert-for-tf2\n","Successfully installed bert-for-tf2-0.14.6 params-flow-0.8.2 py-params-0.9.7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WWRy6PKp04hV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":84},"executionInfo":{"status":"ok","timestamp":1600318139632,"user_tz":-330,"elapsed":7108,"user":{"displayName":"vivek gohel","photoUrl":"","userId":"08799214395694087015"}},"outputId":"59219637-25fe-4dac-8e70-41f48781883e"},"source":["tf.config.list_physical_devices('GPU')\n","print(\"GPU Available: \", tf.test.is_gpu_available())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-2-b783941d6613>:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.config.list_physical_devices('GPU')` instead.\n","GPU Available:  True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RMHqhpwp2VhE","colab_type":"code","colab":{}},"source":["# gs_folder_bert = \"gs://cloud-tpu-checkpoints/bert/keras_bert/uncased_L-12_H-768_A-12\"\n","# tf.io.gfile.listdir(gs_folder_bert)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tLq2X_1dlVWl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":319},"executionInfo":{"status":"ok","timestamp":1600318153065,"user_tz":-330,"elapsed":10468,"user":{"displayName":"vivek gohel","photoUrl":"","userId":"08799214395694087015"}},"outputId":"a2332b40-0c41-4e7e-c0b4-efd4b90e0e33"},"source":["# https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n","if not os.path.exists('/content/drive/My Drive/machine translation/uncased_L-12_H-768_A-12'):\n","  !wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n","  !unzip uncased_L-12_H-768_A-12"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-09-17 04:49:01--  https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.133.128, 108.177.15.128, 173.194.76.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.133.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 407727028 (389M) [application/zip]\n","Saving to: ‘uncased_L-12_H-768_A-12.zip’\n","\n","uncased_L-12_H-768_ 100%[===================>] 388.84M   118MB/s    in 3.5s    \n","\n","2020-09-17 04:49:05 (112 MB/s) - ‘uncased_L-12_H-768_A-12.zip’ saved [407727028/407727028]\n","\n","Archive:  uncased_L-12_H-768_A-12.zip\n","   creating: uncased_L-12_H-768_A-12/\n","  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.meta  \n","  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n","  inflating: uncased_L-12_H-768_A-12/vocab.txt  \n","  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.index  \n","  inflating: uncased_L-12_H-768_A-12/bert_config.json  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qsd5vUeu306a","colab_type":"code","colab":{}},"source":["# hub_url_bert = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h7W3WQFF9qfw","colab_type":"code","colab":{}},"source":["with open('/content/drive/My Drive/machine translation/pol-eng.zip (Unzipped Files)/pol.txt','r') as f:\n","  data = f.read()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g4zdUlgz9qlC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600318168380,"user_tz":-330,"elapsed":4115,"user":{"displayName":"vivek gohel","photoUrl":"","userId":"08799214395694087015"}},"outputId":"0cc0ba4e-779d-44e2-cfa0-7ae20be45111"},"source":["uncleaned_data_list = data.strip().split('\\n')\n","len(uncleaned_data_list)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["40311"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"Jbj7Pwjw9qhg","colab_type":"code","colab":{}},"source":["uncleaned_data_list = uncleaned_data_list[:38695]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_6Uxu4nh9xUv","colab_type":"code","colab":{}},"source":["english_word = []\n","polish_word = []\n","cleaned_data_list = []\n","for word in uncleaned_data_list:\n","  english_word.append(word.split('\\t')[:-1][0])\n","  polish_word.append(word.split('\\t')[:-1][1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ECsM4WOo9xar","colab_type":"code","colab":{}},"source":["data = pd.DataFrame(columns=['English','Polish'])\n","data['English'] = english_word\n","data['Polish'] = polish_word"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2yxn0_Ge9xXy","colab_type":"code","colab":{}},"source":["data.to_csv('data.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P5k9qCBf9xS2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":195},"executionInfo":{"status":"ok","timestamp":1600318168387,"user_tz":-330,"elapsed":3189,"user":{"displayName":"vivek gohel","photoUrl":"","userId":"08799214395694087015"}},"outputId":"ff82e2bc-e770-4bd4-c176-537aacb64bdd"},"source":["data = pd.read_csv('data.csv')\n","data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>English</th>\n","      <th>Polish</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Go.</td>\n","      <td>Idź.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Hi.</td>\n","      <td>Cześć.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Run!</td>\n","      <td>Uciekaj!</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Run.</td>\n","      <td>Biegnij.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Run.</td>\n","      <td>Uciekaj.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  English    Polish\n","0     Go.      Idź.\n","1     Hi.    Cześć.\n","2    Run!  Uciekaj!\n","3    Run.  Biegnij.\n","4    Run.  Uciekaj."]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"jpMk_r0P4uuR","colab_type":"code","colab":{}},"source":["# we will take 80% data in train and remaining in test\n","train = int(len(data)*0.8)\n","test = len(data) - train\n","train_examples, val_examples = data.iloc[0:train,:], data.iloc[train:len(data),:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I7QJxc9y-gk2","colab_type":"code","colab":{}},"source":["english_text = train_examples['English'].values\n","polish_text = train_examples['Polish'].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JgnKup2ka0BK","colab_type":"code","colab":{}},"source":["english_val_text = val_examples['English'].values\n","polish_val_text = val_examples['Polish'].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ukaJBSTNPrau","colab_type":"code","colab":{}},"source":["train_examples = tf.data.Dataset.from_tensor_slices((english_text, polish_text))\n","val_examples = tf.data.Dataset.from_tensor_slices((english_val_text, polish_val_text))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RtkrF-umP1wR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600318168391,"user_tz":-330,"elapsed":1795,"user":{"displayName":"vivek gohel","photoUrl":"","userId":"08799214395694087015"}},"outputId":"33d7e22c-0d76-42e7-d9b4-4b4c2ccd8e6d"},"source":["type(train_examples)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"Nk3RKk4VP7oZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600318168392,"user_tz":-330,"elapsed":1575,"user":{"displayName":"vivek gohel","photoUrl":"","userId":"08799214395694087015"}},"outputId":"7a7bef57-dab8-4d40-900f-f35f0a70364d"},"source":["print(train_examples)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<TensorSliceDataset shapes: ((), ()), types: (tf.string, tf.string)>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pzg9EUw6fntO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1600318168393,"user_tz":-330,"elapsed":1362,"user":{"displayName":"vivek gohel","photoUrl":"","userId":"08799214395694087015"}},"outputId":"c6f36b8c-9bb8-453f-cbce-ae16158e0796"},"source":["for en, pl in train_examples.take(1):\n","  print(tf.compat.as_text(en.numpy()))\n","  print(tf.compat.as_text(pl.numpy()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go.\n","Idź.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rcE2nDFTinsS","colab_type":"code","colab":{}},"source":["def convert_to_unicode(text):\n","    \"\"\"Converts `text` to Unicode (if it's not already), assuming utf-8 input.\"\"\"\n","    if isinstance(text, str):\n","        return text\n","    elif isinstance(text, bytes):\n","        return text.decode(\"utf-8\", \"ignore\")\n","    else:\n","        raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n","\n","\n","def load_vocab(vocab_file):\n","    \"\"\"Loads a vocabulary file into a dictionary.\"\"\"\n","    vocab = collections.OrderedDict()\n","    index = 0\n","    with tf.io.gfile.GFile(vocab_file, \"r\") as reader:\n","        while True:\n","            token = convert_to_unicode(reader.readline())\n","            if not token:\n","                break\n","            token = token.strip()\n","            vocab[token] = index\n","            index += 1\n","    return vocab\n","\n","\n","def whitespace_tokenize(text):\n","    \"\"\"Runs basic whitespace cleaning and splitting on a piece of text.\"\"\"\n","    text = text.strip()\n","    if not text:\n","        return []\n","    tokens = text.split()\n","    return tokens\n","\n","def convert_by_vocab(vocab, items):\n","    \"\"\"Converts a sequence of [tokens|ids] using the vocab.\"\"\"\n","    output = []\n","    for item in items:\n","        output.append(vocab[item])\n","    return output\n","\n","class FullTokenizer(object):\n","    \"\"\"Runs end-to-end tokenziation.\"\"\"\n","\n","    def __init__(self, vocab_file, do_lower_case=True):\n","        self.vocab = load_vocab(vocab_file)\n","        self.inv_vocab = {v: k for k, v in self.vocab.items()}\n","        self.basic_tokenizer = BasicTokenizer(do_lower_case=do_lower_case)\n","        self.wordpiece_tokenizer = WordpieceTokenizer(vocab=self.vocab)\n","\n","    def tokenize(self, text):\n","        split_tokens = []\n","        for token in self.basic_tokenizer.tokenize(text):\n","            for sub_token in self.wordpiece_tokenizer.tokenize(token):\n","                split_tokens.append(sub_token)\n","\n","        return split_tokens\n","    \n","    def convert_tokens_to_ids(self, tokens):\n","        return convert_by_vocab(self.vocab, tokens)\n","\n","    def convert_ids_to_tokens(self, ids):\n","        return convert_by_vocab(self.inv_vocab, ids)\n","\n","\n","class BasicTokenizer(object):\n","    \"\"\"Runs basic tokenization (punctuation splitting, lower casing, etc.).\"\"\"\n","\n","    def __init__(self, do_lower_case=True):\n","        \"\"\"Constructs a BasicTokenizer.\n","    \n","        Args:\n","          do_lower_case: Whether to lower case the input.\n","        \"\"\"\n","        self.do_lower_case = do_lower_case\n","\n","    def tokenize(self, text):\n","        \"\"\"Tokenizes a piece of text.\"\"\"\n","        text = convert_to_unicode(text)\n","        text = self._clean_text(text)\n","\n","        # This was added on November 1st, 2018 for the multilingual and Chinese\n","        # models. This is also applied to the English models now, but it doesn't\n","        # matter since the English models were not trained on any Chinese data\n","        # and generally don't have any Chinese data in them (there are Chinese\n","        # characters in the vocabulary because Wikipedia does have some Chinese\n","        # words in the English Wikipedia.).\n","        text = self._tokenize_chinese_chars(text)\n","\n","        orig_tokens = whitespace_tokenize(text)\n","        split_tokens = []\n","        for token in orig_tokens:\n","            if self.do_lower_case:\n","                token = token.lower()\n","                token = self._run_strip_accents(token)\n","            split_tokens.extend(self._run_split_on_punc(token))\n","\n","        output_tokens = whitespace_tokenize(\" \".join(split_tokens))\n","        return output_tokens\n","\n","    def _run_strip_accents(self, text):\n","        \"\"\"Strips accents from a piece of text.\"\"\"\n","        text = unicodedata.normalize(\"NFD\", text)\n","        output = []\n","        for char in text:\n","            cat = unicodedata.category(char)\n","            if cat == \"Mn\":\n","                continue\n","            output.append(char)\n","        return \"\".join(output)\n","\n","    def _run_split_on_punc(self, text):\n","        \"\"\"Splits punctuation on a piece of text.\"\"\"\n","        chars = list(text)\n","        i = 0\n","        start_new_word = True\n","        output = []\n","        while i < len(chars):\n","            char = chars[i]\n","            if _is_punctuation(char):\n","                output.append([char])\n","                start_new_word = True\n","            else:\n","                if start_new_word:\n","                    output.append([])\n","                start_new_word = False\n","                output[-1].append(char)\n","            i += 1\n","\n","        return [\"\".join(x) for x in output]\n","\n","    def _tokenize_chinese_chars(self, text):\n","        \"\"\"Adds whitespace around any CJK character.\"\"\"\n","        output = []\n","        for char in text:\n","            cp = ord(char)\n","            if self._is_chinese_char(cp):\n","                output.append(\" \")\n","                output.append(char)\n","                output.append(\" \")\n","            else:\n","                output.append(char)\n","        return \"\".join(output)\n","\n","    def _is_chinese_char(self, cp):\n","        \"\"\"Checks whether CP is the codepoint of a CJK character.\"\"\"\n","        # This defines a \"chinese character\" as anything in the CJK Unicode block:\n","        #   https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)\n","        #\n","        # Note that the CJK Unicode block is NOT all Japanese and Korean characters,\n","        # despite its name. The modern Korean Hangul alphabet is a different block,\n","        # as is Japanese Hiragana and Katakana. Those alphabets are used to write\n","        # space-separated words, so they are not treated specially and handled\n","        # like the all of the other languages.\n","        if ((cp >= 0x4E00 and cp <= 0x9FFF) or  #\n","                (cp >= 0x3400 and cp <= 0x4DBF) or  #\n","                (cp >= 0x20000 and cp <= 0x2A6DF) or  #\n","                (cp >= 0x2A700 and cp <= 0x2B73F) or  #\n","                (cp >= 0x2B740 and cp <= 0x2B81F) or  #\n","                (cp >= 0x2B820 and cp <= 0x2CEAF) or\n","                (cp >= 0xF900 and cp <= 0xFAFF) or  #\n","                (cp >= 0x2F800 and cp <= 0x2FA1F)):  #\n","            return True\n","\n","        return False\n","\n","    def _clean_text(self, text):\n","        \"\"\"Performs invalid character removal and whitespace cleanup on text.\"\"\"\n","        output = []\n","        for char in text:\n","            cp = ord(char)\n","            if cp == 0 or cp == 0xfffd or _is_control(char):\n","                continue\n","            if _is_whitespace(char):\n","                output.append(\" \")\n","            else:\n","                output.append(char)\n","        return \"\".join(output)\n","\n","\n","class WordpieceTokenizer(object):\n","    \"\"\"Runs WordPiece tokenziation.\"\"\"\n","\n","    def __init__(self, vocab, unk_token=\"[UNK]\", max_input_chars_per_word=200):\n","        self.vocab = vocab\n","        self.unk_token = unk_token\n","        self.max_input_chars_per_word = max_input_chars_per_word\n","\n","    def tokenize(self, text):\n","        \"\"\"Tokenizes a piece of text into its word pieces.\n","    \n","        This uses a greedy longest-match-first algorithm to perform tokenization\n","        using the given vocabulary.\n","    \n","        For example:\n","          input = \"unaffable\"\n","          output = [\"un\", \"##aff\", \"##able\"]\n","    \n","        Args:\n","          text: A single token or whitespace separated tokens. This should have\n","            already been passed through `BasicTokenizer.\n","    \n","        Returns:\n","          A list of wordpiece tokens.\n","        \"\"\"\n","\n","        text = convert_to_unicode(text)\n","\n","        output_tokens = []\n","        for token in whitespace_tokenize(text):\n","            chars = list(token)\n","            if len(chars) > self.max_input_chars_per_word:\n","                output_tokens.append(self.unk_token)\n","                continue\n","\n","            is_bad = False\n","            start = 0\n","            sub_tokens = []\n","            while start < len(chars):\n","                end = len(chars)\n","                cur_substr = None\n","                while start < end:\n","                    substr = \"\".join(chars[start:end])\n","                    if start > 0:\n","                        substr = \"##\" + substr\n","                    if substr in self.vocab:\n","                        cur_substr = substr\n","                        break\n","                    end -= 1\n","                if cur_substr is None:\n","                    is_bad = True\n","                    break\n","                sub_tokens.append(cur_substr)\n","                start = end\n","\n","            if is_bad:\n","                output_tokens.append(self.unk_token)\n","            else:\n","                output_tokens.extend(sub_tokens)\n","        return output_tokens\n","\n","def _is_whitespace(char):\n","    \"\"\"Checks whether `chars` is a whitespace character.\"\"\"\n","    # \\t, \\n, and \\r are technically contorl characters but we treat them\n","    # as whitespace since they are generally considered as such.\n","    if char == \" \" or char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n","        return True\n","    cat = unicodedata.category(char)\n","    if cat == \"Zs\":\n","        return True\n","    return False\n","\n","\n","def _is_control(char):\n","    \"\"\"Checks whether `chars` is a control character.\"\"\"\n","    # These are technically control characters but we count them as whitespace\n","    # characters.\n","    if char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n","        return False\n","    cat = unicodedata.category(char)\n","    if cat.startswith(\"C\"):\n","        return True\n","    return False\n","\n","\n","def _is_punctuation(char):\n","    \"\"\"Checks whether `chars` is a punctuation character.\"\"\"\n","    cp = ord(char)\n","    # We treat all non-letter/number ASCII as punctuation.\n","    # Characters such as \"^\", \"$\", and \"`\" are not in the Unicode\n","    # Punctuation class but we treat them as punctuation anyways, for\n","    # consistency.\n","    if ((cp >= 33 and cp <= 47) or (cp >= 58 and cp <= 64) or\n","            (cp >= 91 and cp <= 96) or (cp >= 123 and cp <= 126)):\n","        return True\n","    cat = unicodedata.category(char)\n","    if cat.startswith(\"P\"):\n","        return True\n","    return False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JLljBxjoBgyF","colab_type":"text"},"source":["Create a custom subwords tokenizer from the training dataset for the decoder."]},{"cell_type":"code","metadata":{"id":"WBBXMc1JAyjY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":151},"executionInfo":{"status":"ok","timestamp":1600318200437,"user_tz":-330,"elapsed":32158,"user":{"displayName":"vivek gohel","photoUrl":"","userId":"08799214395694087015"}},"outputId":"822c9494-91f1-4227-d562-f1bbadf11ae9"},"source":["vocab_file = '/content/drive/My Drive/machine translation/vocab_pl'\n","if os.path.isfile(vocab_file + '.subwords'):\n","  tokenizer_pl = tfds.features.text.SubwordTextEncoder.load_from_file(vocab_file)\n","else: \n","  tokenizer_pl = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n","      (polish_text), target_vocab_size=2 ** 13)\n","  tokenizer_pl.save_to_file('vocab_pl')\n","\n","sample_string = 'Transformer jest niesamowity.'\n","tokenized_string = tokenizer_pl.encode(sample_string)\n","for ts in tokenized_string:\n","  print ('{} ----> {}'.format(ts, tokenizer_pl.decode([ts])))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["4779 ----> Tra\n","1876 ----> ns\n","2376 ----> form\n","617 ----> er\n","8241 ---->  \n","5 ----> jest \n","4475 ----> niesamowity\n","8255 ----> .\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"g9TNXY2ACdtx","colab_type":"text"},"source":["The encoder uses BERT tokenizer."]},{"cell_type":"code","metadata":{"id":"GWrGN9LbBRJB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1600318200439,"user_tz":-330,"elapsed":28583,"user":{"displayName":"vivek gohel","photoUrl":"","userId":"08799214395694087015"}},"outputId":"b5d76a85-7b38-48ac-d9ef-cd95c5960628"},"source":["tokenizer_en = FullTokenizer(\n","    vocab_file= 'uncased_L-12_H-768_A-12/vocab.txt',\n","    do_lower_case=True)\n","\n","test_tokens = tokenizer_en.tokenize(english_text[-1])\n","test_ids = tokenizer_en.convert_tokens_to_ids(['[CLS]'] + test_tokens + ['[SEP]'])\n","print(test_ids)\n","print(tokenizer_en.convert_ids_to_tokens(test_ids))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[101, 2016, 2001, 2200, 11471, 2076, 1996, 8835, 1012, 102]\n","['[CLS]', 'she', 'was', 'very', 'bored', 'during', 'the', 'lecture', '.', '[SEP]']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EfYY2DUnDHXg","colab_type":"code","colab":{}},"source":["MAX_SEQ_LENGTH = 50\n","\n","\n","def encode(en, pl, seq_length=MAX_SEQ_LENGTH):\n","  tokens_en = tokenizer_en.tokenize(tf.compat.as_text(en.numpy()))\n","  lang1 = tokenizer_en.convert_tokens_to_ids(['[CLS]'] + tokens_en + ['[SEP]'])\n","  if len(lang1)<seq_length:\n","    lang1 = lang1 + list(np.zeros(seq_length - len(lang1), 'int32'))\n","\n","  lang2 = [tokenizer_pl.vocab_size] + tokenizer_pl.encode(tf.compat.as_text(pl.numpy())) + [tokenizer_pl.vocab_size + 1]\n","  if len(lang2)<seq_length:\n","    lang2 = lang2 + list(np.zeros(seq_length - len(lang2), 'int32'))\n","\n","  return lang1, lang2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1PmzrCbQ1G2h","colab_type":"code","colab":{}},"source":["def tf_encode(en, pl):\n","  result_en, result_pl = tf.py_function(encode, [en, pl], [tf.int32, tf.int32])\n","  result_en.set_shape([None])\n","  result_pl.set_shape([None])\n","\n","  return result_en, result_pl"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FYe-JQhYM2Yw","colab_type":"code","colab":{}},"source":["def filter_max_length(x, y, max_length=MAX_SEQ_LENGTH):\n","  return tf.logical_and(tf.size(x) <= max_length,\n","                        tf.size(y) <= max_length)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0NZobGISNf6U","colab_type":"text"},"source":["encode text into integers"]},{"cell_type":"code","metadata":{"id":"qHPwB7mAigh5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600318207794,"user_tz":-330,"elapsed":1689,"user":{"displayName":"vivek gohel","photoUrl":"","userId":"08799214395694087015"}},"outputId":"77726949-499e-4541-ec18-c09ee17f6950"},"source":["print(len(train_examples))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["30956\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PsZ3SLIuaew6","colab_type":"code","colab":{}},"source":["BUFFER_SIZE = 40000\n","BATCH_SIZE = 64\n","\n","train_dataset = train_examples.map(tf_encode)\n","# train_dataset = tf.io.decode_raw(train_dataset, tf.int32)\n","train_dataset = train_dataset.filter(filter_max_length)\n","\n","# cache the dataset to memory to get a speedup while reading from it.\n","train_dataset = train_dataset.cache()\n","train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(\n","    BATCH_SIZE, padded_shapes=([-1], [-1]), drop_remainder=True)\n","train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n","\n","val_dataset = val_examples.map(\n","    lambda en, pl: tf.py_function(encode, [en, pl], [tf.int32, tf.int32]))\n","val_dataset = val_dataset.filter(filter_max_length)\n","val_dataset = val_dataset.padded_batch(BATCH_SIZE, padded_shapes=([-1], [-1]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0palIefv5pN-","colab_type":"text"},"source":["Positional encoding\n","\n","Since this model doesn't contain any recurrence or convolution, positional encoding is added to give the model some information about the relative position of the words in the sentence.\n","\n","The positional encoding vector is added to the embedding vector. Embeddings represent a token in a d-dimensional space where tokens with similar meaning will be closer to each other. But the embeddings do not encode the relative position of words in a sentence. So after adding the positional encoding, words will be closer to each other based on the similarity of their meaning and their position in the sentence, in the d-dimensional space."]},{"cell_type":"code","metadata":{"id":"RPMk00Wucd2b","colab_type":"code","colab":{}},"source":["def get_angles(pos, i, d_model):\n","  angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n","  return pos * angle_rates"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0WfjEzy96xzC","colab_type":"code","colab":{}},"source":["def positional_encoding(position, d_model):\n","    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n","                            np.arange(d_model)[np.newaxis, :],\n","                            d_model)\n","\n","    # apply sin to even indices in the array; 2i\n","    sines = np.sin(angle_rads[:, 0::2])\n","\n","    # apply cos to odd indices in the array; 2i+1\n","    cosines = np.cos(angle_rads[:, 1::2])\n","\n","    pos_encoding = np.concatenate([sines, cosines], axis=-1)\n","\n","    pos_encoding = pos_encoding[np.newaxis, ...]\n","\n","    return tf.cast(pos_encoding, dtype=tf.float32)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0EWQCJtQ9Bua","colab_type":"text"},"source":["Masking\n","\n","Mask all the pad tokens in the batch of sequence. It ensures that the model does not treat padding as the input. The mask indicates where pad value 0 is present: it outputs a 1 at those locations, and a 0 otherwise."]},{"cell_type":"code","metadata":{"id":"TSiePM7Z80Zn","colab_type":"code","colab":{}},"source":["def create_padding_mask(seq):\n","  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n","  \n","  # add extra dimensions so that we can add the padding\n","  # to the attention logits.\n","  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Dy72mDGH9xJo","colab_type":"text"},"source":["The look-ahead mask is used to mask the future tokens in a sequence. In other words, the mask indicates which entries should not be used.\n","\n","This means that to predict the third word, only the first and second word will be used. Similarly to predict the fourth word, only the first, second and the third word will be used and so on."]},{"cell_type":"code","metadata":{"id":"3ZIQXnv19pqE","colab_type":"code","colab":{}},"source":["def create_look_ahead_mask(size):\n","    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n","    return mask  # (seq_len, seq_len)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9RkQR6BN_Ggo","colab_type":"text"},"source":["Scaled dot product attention"]},{"cell_type":"code","metadata":{"id":"u_k9cQyN_DDq","colab_type":"code","colab":{}},"source":["def scaled_dot_product_attention(q, k, v, mask):\n","    \"\"\"Calculate the attention weights.\n","    q, k, v must have matching leading dimensions.\n","    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n","    The mask has different shapes depending on its type(padding or look ahead) \n","    but it must be broadcastable for addition.\n","    \n","    Args:\n","      q: query shape == (..., seq_len_q, depth)\n","      k: key shape == (..., seq_len_k, depth)\n","      v: value shape == (..., seq_len_v, depth_v)\n","      mask: Float tensor with shape broadcastable \n","            to (..., seq_len_q, seq_len_k). Defaults to None.\n","      \n","    Returns:\n","      output, attention_weights\n","    \"\"\"\n","\n","    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n","\n","    # scale matmul_qk\n","    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n","    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n","\n","    # add the mask to the scaled tensor.\n","    if mask is not None:\n","        scaled_attention_logits += (mask * -1e9)\n","\n","        # softmax is normalized on the last axis (seq_len_k) so that the scores\n","    # add up to 1.\n","    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n","\n","    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n","\n","    return output, attention_weights"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GqQVkj-0A5M2","colab_type":"text"},"source":["Multi-Head-Attention"]},{"cell_type":"code","metadata":{"id":"34Tc_cOyA34j","colab_type":"code","colab":{}},"source":["class MultiHeadAttention(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads):\n","        super(MultiHeadAttention, self).__init__()\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","\n","        assert d_model % self.num_heads == 0\n","\n","        self.depth = d_model // self.num_heads\n","\n","        self.wq = tf.keras.layers.Dense(d_model)\n","        self.wk = tf.keras.layers.Dense(d_model)\n","        self.wv = tf.keras.layers.Dense(d_model)\n","\n","        self.dense = tf.keras.layers.Dense(d_model)\n","\n","    def split_heads(self, x, batch_size):\n","        \"\"\"Split the last dimension into (num_heads, depth).\n","        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n","        \"\"\"\n","        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","        return tf.transpose(x, perm=[0, 2, 1, 3])\n","\n","    def call(self, v, k, q, mask):\n","        batch_size = tf.shape(q)[0]\n","\n","        q = self.wq(q)  # (batch_size, seq_len, d_model)\n","        k = self.wk(k)  # (batch_size, seq_len, d_model)\n","        v = self.wv(v)  # (batch_size, seq_len, d_model)\n","\n","        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n","        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n","        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n","\n","        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n","        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n","        scaled_attention, attention_weights = scaled_dot_product_attention(\n","            q, k, v, mask)\n","\n","        scaled_attention = tf.transpose(scaled_attention,\n","                                        perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n","\n","        concat_attention = tf.reshape(scaled_attention,\n","                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n","\n","        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n","\n","        return output, attention_weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uwaImqo7Ezmv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600318219993,"user_tz":-330,"elapsed":3613,"user":{"displayName":"vivek gohel","photoUrl":"","userId":"08799214395694087015"}},"outputId":"3fcd301b-afb1-4d01-a8f5-7ea7aa0016dd"},"source":["temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n","y = tf.random.uniform((1, 60, 768))  # (batch_size, encoder_sequence, d_model)\n","q = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n","out, attn = temp_mha(y, k=y, q=q, mask=None)\n","out.shape, attn.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"qn32g9ImFYyq","colab_type":"text"},"source":["Point wise feed forward network\n","\n","Point wise feed forward network consists of two fully-connected layers with a ReLU activation in between."]},{"cell_type":"code","metadata":{"id":"TXqxI4aRE8so","colab_type":"code","colab":{}},"source":["def point_wise_feed_forward_network(d_model, dff):\n","    return tf.keras.Sequential([\n","        tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n","        tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n","    ])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ukSu6sMzGSVX","colab_type":"text"},"source":["Encoder Layer and Encoder\n","\n","Use bert as encoder. The output shape is (batch_size, input_seq_len, d_model)."]},{"cell_type":"code","metadata":{"id":"gCmPXLfLGRRk","colab_type":"code","colab":{}},"source":["def build_encoder(config_file):\n","    with tf.io.gfile.GFile(config_file, \"r\") as reader:\n","        stock_params = StockBertConfig.from_json_string(reader.read())\n","        bert_params = stock_params.to_bert_model_layer_params()\n","\n","    return BertModelLayer.from_params(bert_params, name=\"bert\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NJFVE71aIBgC","colab_type":"text"},"source":["Decoder Layer and Decoder\n","\n","\n","Each decoder layer consists of sublayers:\n","\n","1.) Masked multi-head attention (with look ahead mask and padding mask)\n","\n","2.) Multi-head attention (with padding mask). V (value) and K (key) receive the encoder output as inputs. Q (query) receives the output from the masked multi-head attention sublaye\n","\n","3.) Point wise feed forward networks\n","\n","Each of these sublayers has a residual connection around it followed by a layer normalization. The output of each sublayer is LayerNorm(x + Sublayer(x)). The normalization is done on the d_model (last) axis."]},{"cell_type":"code","metadata":{"id":"m_1imOn1Hw65","colab_type":"code","colab":{}},"source":["class DecoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads, dff, rate=0.1):\n","        super(DecoderLayer, self).__init__()\n","\n","        self.mha1 = MultiHeadAttention(d_model, num_heads)\n","        self.mha2 = MultiHeadAttention(d_model, num_heads)\n","\n","        self.ffn = point_wise_feed_forward_network(d_model, dff)\n","\n","        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","\n","        self.dropout1 = tf.keras.layers.Dropout(rate)\n","        self.dropout2 = tf.keras.layers.Dropout(rate)\n","        self.dropout3 = tf.keras.layers.Dropout(rate)\n","\n","\n","    def call(self, x, enc_output, training,\n","             look_ahead_mask, padding_mask):\n","        # enc_output.shape == (batch_size, input_seq_len, d_model)\n","\n","        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n","        attn1 = self.dropout1(attn1, training=training)\n","        out1 = self.layernorm1(attn1 + x)\n","\n","        attn2, attn_weights_block2 = self.mha2(\n","            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n","        attn2 = self.dropout2(attn2, training=training)\n","        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n","\n","        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n","        ffn_output = self.dropout3(ffn_output, training=training)\n","        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n","\n","        return out3, attn_weights_block1, attn_weights_block2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mMS8ZpEfKAQT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600318219997,"user_tz":-330,"elapsed":2386,"user":{"displayName":"vivek gohel","photoUrl":"","userId":"08799214395694087015"}},"outputId":"45527ae1-def4-4718-892e-177762851d5c"},"source":["sample_decoder_layer = DecoderLayer(512, 8, 2048)\n","sample_encoder_output = tf.random.uniform((64, 128, 768))\n","\n","sample_decoder_layer_output, _, _ = sample_decoder_layer(\n","    tf.random.uniform((64, 50, 512)), sample_encoder_output,\n","    False, None, None)\n","\n","sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([64, 50, 512])"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"markdown","metadata":{"id":"zs-E_WA5MeYK","colab_type":"text"},"source":["The Decoder consists of: 1. Output Embedding 2. Positional Encoding 3. N decoder layers"]},{"cell_type":"code","metadata":{"id":"xJOI2tTOL-WC","colab_type":"code","colab":{}},"source":["class Decoder(tf.keras.layers.Layer):\n","    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n","                 rate=0.1):\n","        super(Decoder, self).__init__()\n","\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","\n","        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n","        self.pos_encoding = positional_encoding(target_vocab_size, self.d_model)\n","\n","        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n","                           for _ in range(num_layers)]\n","        self.dropout = tf.keras.layers.Dropout(rate)\n","\n","    def call(self, x, enc_output, training,\n","             look_ahead_mask, padding_mask):\n","        seq_len = tf.shape(x)[1]\n","        attention_weights = {}\n","\n","        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n","        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        x += self.pos_encoding[:, :seq_len, :]\n","\n","        x = self.dropout(x, training=training)\n","\n","        for i in range(self.num_layers):\n","            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n","                                                   look_ahead_mask, padding_mask)\n","\n","            attention_weights['decoder_layer{}_block1'.format(i + 1)] = block1\n","            attention_weights['decoder_layer{}_block2'.format(i + 1)] = block2\n","\n","        # x.shape == (batch_size, target_seq_len, d_model)\n","        return x, attention_weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fSfhhdomR7QE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600318221578,"user_tz":-330,"elapsed":3436,"user":{"displayName":"vivek gohel","photoUrl":"","userId":"08799214395694087015"}},"outputId":"902bee0d-c906-4170-fbbf-eb4c65bf8bc2"},"source":["sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, \n","                         dff=2048, target_vocab_size=8000)\n","\n","output, attn = sample_decoder(tf.random.uniform((64, 26)), \n","                              enc_output=sample_encoder_output, \n","                              training=False, look_ahead_mask=None, \n","                              padding_mask=None)\n","\n","output.shape, attn['decoder_layer2_block2'].shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 128]))"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"markdown","metadata":{"id":"-ZoN20yDTtoI","colab_type":"text"},"source":["Create the Transformer\n","\n","Transformer consists of the encoder, decoder and a final linear layer. The output of the decoder is the input to the linear layer and its output is returned."]},{"cell_type":"code","metadata":{"id":"8T_5WttkSIx8","colab_type":"code","colab":{}},"source":["class Config(object):\n","  def __init__(self, num_layers, d_model, dff, num_heads):\n","    self.num_layers = num_layers\n","    self.d_model = d_model\n","    self.dff = dff\n","    self.num_heads= num_heads"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kqS4gNABUK0K","colab_type":"code","colab":{}},"source":["from bert.loader import map_to_stock_variable_name\n","# /content/drive/My Drive/machine translation/transformer/bert\n","class Transformer(tf.keras.Model):\n","  def __init__(self, config,\n","               target_vocab_size, \n","               bert_config_file,\n","               bert_training=False, \n","               rate=0.1,\n","               name='transformer'):\n","      super(Transformer, self).__init__(name=name)\n","\n","      self.encoder = build_encoder(config_file=bert_config_file)\n","      self.encoder.trainable = bert_training\n","\n","      self.decoder = Decoder(config.num_layers, config.d_model, \n","                             config.num_heads, config.dff, target_vocab_size, rate)\n","\n","      self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n","\n","\n","  def load_stock_weights(self, bert: BertModelLayer, ckpt_file):\n","      assert isinstance(bert, BertModelLayer), \"Expecting a BertModelLayer instance as first argument\"\n","      assert tf.compat.v1.train.checkpoint_exists(ckpt_file), \"Checkpoint does not exist: {}\".format(ckpt_file)\n","      ckpt_reader = tf.train.load_checkpoint(ckpt_file)\n","\n","      bert_prefix = 'transformer/bert'\n","\n","      weights = []\n","      for weight in bert.weights:\n","          stock_name = map_to_stock_variable_name(weight.name, bert_prefix)\n","          if ckpt_reader.has_tensor(stock_name):\n","              value = ckpt_reader.get_tensor(stock_name)\n","              weights.append(value)\n","          else:\n","              raise ValueError(\"No value for:[{}], i.e.:[{}] in:[{}]\".format(weight.name, stock_name, ckpt_file))\n","      bert.set_weights(weights)\n","      print(\"Done loading {} BERT weights from: {} into {} (prefix:{})\".format(\n","          len(weights), ckpt_file, bert, bert_prefix))\n","\n","  def restore_encoder(self, bert_ckpt_file):\n","      # loading the original pre-trained weights into the BERT layer:\n","      self.load_stock_weights(self.encoder, bert_ckpt_file)\n","\n","  def call(self, inp, tar, training, look_ahead_mask, dec_padding_mask):\n","      enc_output = self.encoder(inp, training=self.encoder.trainable)  # (batch_size, inp_seq_len, d_model)\n","\n","      # dec_output.shape == (batch_size, tar_seq_len, d_model)\n","      dec_output, attention_weights = self.decoder(\n","          tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n","\n","      final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n","\n","      return final_output, attention_weights"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nMFJQGp2Zqco","colab_type":"text"},"source":["Set hyperparameters"]},{"cell_type":"code","metadata":{"id":"ViVrUV_MZmJI","colab_type":"code","colab":{}},"source":["target_vocab_size = tokenizer_pl.vocab_size + 2\n","dropout_rate = 0.15\n","config = Config(num_layers=6, d_model=512, dff=1024, num_heads=8)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9G7IkUmFaBWa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":188},"executionInfo":{"status":"ok","timestamp":1600318223256,"user_tz":-330,"elapsed":4000,"user":{"displayName":"vivek gohel","photoUrl":"","userId":"08799214395694087015"}},"outputId":"dbc07bd6-082e-4b5c-92a1-a932a7cc3ba9"},"source":["# gs_folder_bert\n","# uncased_L-12_H-768_A-12\n","MODEL_DIR = \"uncased_L-12_H-768_A-12\"\n","bert_config_file = os.path.join(MODEL_DIR, \"bert_config.json\")\n","bert_ckpt_file = os.path.join(MODEL_DIR, 'bert_model.ckpt')\n","\n","# with tpu_strategy.scope():\n","transformer = Transformer(config=config,\n","                          target_vocab_size=target_vocab_size,\n","                          bert_config_file=bert_config_file)\n","  \n","inp = tf.random.uniform((BATCH_SIZE, MAX_SEQ_LENGTH))\n","tar_inp = tf.random.uniform((BATCH_SIZE, MAX_SEQ_LENGTH))\n","fn_out, _ = transformer(inp, tar_inp, \n","                        True,\n","                        look_ahead_mask=None,\n","                        dec_padding_mask=None)\n","print(tar_inp.shape) # (batch_size, tar_seq_len) \n","print(fn_out.shape)  # (batch_size, tar_seq_len, target_vocab_size) \n","\n","# init bert pre-trained weights\n","transformer.restore_encoder(bert_ckpt_file)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(64, 50)\n","(64, 50, 8467)\n","WARNING:tensorflow:From <ipython-input-42-c616cf2f44b4>:23: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-42-c616cf2f44b4>:23: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n"],"name":"stderr"},{"output_type":"stream","text":["Done loading 196 BERT weights from: uncased_L-12_H-768_A-12/bert_model.ckpt into <bert.model.BertModelLayer object at 0x7fb16cbb6ef0> (prefix:transformer/bert)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o8VkHOG6a86G","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":252},"executionInfo":{"status":"ok","timestamp":1600318223258,"user_tz":-330,"elapsed":3848,"user":{"displayName":"vivek gohel","photoUrl":"","userId":"08799214395694087015"}},"outputId":"f255f125-1d56-4afd-968a-4ccd817cc6dc"},"source":["transformer.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"transformer\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","bert (BertModelLayer)        multiple                  108890112 \n","_________________________________________________________________\n","decoder_1 (Decoder)          multiple                  24834560  \n","_________________________________________________________________\n","dense_94 (Dense)             multiple                  4343571   \n","=================================================================\n","Total params: 138,068,243\n","Trainable params: 29,178,131\n","Non-trainable params: 108,890,112\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UJHv9f6bnam0","colab_type":"text"},"source":["Optimizer\n","\n","Use the Adam optimizer with a custom learning rate scheduler according to the formula in the paper."]},{"cell_type":"code","metadata":{"id":"uWNKXh4QhX8n","colab_type":"code","colab":{}},"source":["class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","    def __init__(self, d_model, warmup_steps=4000):\n","        super(CustomSchedule, self).__init__()\n","\n","        self.d_model = d_model\n","        self.d_model = tf.cast(self.d_model, tf.float32)\n","\n","        self.warmup_steps = warmup_steps\n","    \n","    def __call__(self, step):\n","        arg1 = tf.math.rsqrt(step)\n","        arg2 = step * (self.warmup_steps ** -1.5)\n","\n","        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DZ96j3NFngT2","colab_type":"code","colab":{}},"source":["learning_rate = CustomSchedule(config.d_model)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n","                                     epsilon=1e-9)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MFm_rfNFnizx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":296},"executionInfo":{"status":"ok","timestamp":1600318228240,"user_tz":-330,"elapsed":1513,"user":{"displayName":"vivek gohel","photoUrl":"","userId":"08799214395694087015"}},"outputId":"8c926083-f2e3-4392-a6df-2ecb8f1bfe46"},"source":["temp_learning_rate_schedule = CustomSchedule(config.d_model)\n","import matplotlib.pyplot as plt\n","\n","plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n","plt.ylabel(\"Learning Rate\")\n","plt.xlabel(\"Train Step\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0.5, 0, 'Train Step')"]},"metadata":{"tags":[]},"execution_count":48},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"3ylc9cR8ny7_","colab_type":"text"},"source":["Loss and metrics\n","\n","Since the target sequences are padded, it is important to apply a padding mask when calculating the loss."]},{"cell_type":"code","metadata":{"id":"iipWZI3nnk5G","colab_type":"code","colab":{}},"source":["loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=True, reduction='none')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L02cX2-en5OM","colab_type":"code","colab":{}},"source":["def loss_function(real, pred):\n","    mask = tf.math.logical_not(tf.math.equal(real, 0))\n","    loss_ = loss_object(real, pred)\n","\n","    mask = tf.cast(mask, dtype=loss_.dtype)\n","    loss_ *= mask\n","\n","    return tf.reduce_mean(loss_)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ARXqhIerrguy","colab_type":"code","colab":{}},"source":["train_loss = tf.keras.metrics.Mean(name='train_loss')\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n","    name='train_accuracy')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4XLfgIUGoCnX","colab_type":"text"},"source":["Training and checkpointing\n","\n","Create the checkpoint path and the checkpoint manager. This will be used to save checkpoints every n epochs."]},{"cell_type":"code","metadata":{"id":"PgDgXeRhn7us","colab_type":"code","colab":{}},"source":["checkpoint_path = \"/content/drive/My Drive/machine translation/checkpoints/train\"\n","\n","ckpt = tf.train.Checkpoint(transformer=transformer,\n","                           optimizer=optimizer)\n","\n","ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n","\n","# if a checkpoint exists, restore the latest checkpoint.\n","if ckpt_manager.latest_checkpoint:\n","    ckpt.restore(ckpt_manager.latest_checkpoint)\n","    print('Latest checkpoint restored!!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T6GOjzpzoZKO","colab_type":"text"},"source":["During training this example uses teacher-forcing (like in the text generation tutorial). Teacher forcing is passing the true output to the next time step regardless of what the model predicts at the current time step.\n","\n","As the transformer predicts each word, self-attention allows it to look at the previous words in the input sequence to better predict the next word.\n","\n","To prevent the model from peaking at the expected output the model uses a look-ahead mask."]},{"cell_type":"code","metadata":{"id":"a6JRz2HyoWfv","colab_type":"code","colab":{}},"source":["def create_masks(inp, tar):\n","    # Used in the 2nd attention block in the decoder.\n","    # This padding mask is used to mask the encoder outputs.\n","    dec_padding_mask = create_padding_mask(inp)\n","\n","    # Used in the 1st attention block in the decoder.\n","    # It is used to pad and mask future tokens in the input received by \n","    # the decoder.\n","    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n","    dec_target_padding_mask = create_padding_mask(tar)\n","    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n","\n","    return combined_mask, dec_padding_mask"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"09Ct51nbo6V7","colab_type":"code","colab":{}},"source":["@tf.function\n","def train_step(inp, tar):\n","    tar_inp = tar[:, :-1]\n","    tar_real = tar[:, 1:]\n","\n","    combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n","\n","    \n","    with tf.GradientTape() as tape:\n","        predictions, _ = transformer(inp, tar_inp, \n","                                     True,\n","                                     combined_mask,\n","                                     dec_padding_mask)\n","        loss = loss_function(tar_real, predictions)\n","\n","    gradients = tape.gradient(loss, transformer.trainable_variables)\n","    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n","\n","    train_loss(loss)\n","    train_accuracy(tar_real, predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sqWB00j5qz2E","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":941},"executionInfo":{"status":"ok","timestamp":1600319831871,"user_tz":-330,"elapsed":1583503,"user":{"displayName":"vivek gohel","photoUrl":"","userId":"08799214395694087015"}},"outputId":"26d6d025-144e-4dce-b451-b8eb67deafa7"},"source":["EPOCHS = 11\n","\n","for epoch in range(EPOCHS):\n","    start = time.time()\n","\n","    train_loss.reset_states()\n","    train_accuracy.reset_states()\n","\n","    # inp -> chinese, tar -> english\n","    for (batch, (inp, tar)) in enumerate(train_dataset):\n","        train_step(inp, tar)\n","\n","        if batch % 500 == 0:\n","            print('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n","                epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n","\n","    if (epoch + 1) % 1 == 0:\n","        ckpt_save_path = ckpt_manager.save()\n","        print('Saving checkpoint for epoch {} at {}'.format(epoch + 1,\n","                                                            ckpt_save_path))\n","\n","    print('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1,\n","                                                        train_loss.result(),\n","                                                        train_accuracy.result()))\n","\n","    print('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1 Batch 0 Loss 1.3836 Accuracy 0.0000\n","Saving checkpoint for epoch 1 at /content/drive/My Drive/machine translation/checkpoints/train/ckpt-1\n","Epoch 1 Loss 0.9935 Accuracy 0.0367\n","Time taken for 1 epoch: 176.7250096797943 secs\n","\n","Epoch 2 Batch 0 Loss 0.8912 Accuracy 0.0545\n","Saving checkpoint for epoch 2 at /content/drive/My Drive/machine translation/checkpoints/train/ckpt-2\n","Epoch 2 Loss 0.6987 Accuracy 0.0602\n","Time taken for 1 epoch: 140.0677101612091 secs\n","\n","Epoch 3 Batch 0 Loss 0.5612 Accuracy 0.0673\n","Saving checkpoint for epoch 3 at /content/drive/My Drive/machine translation/checkpoints/train/ckpt-3\n","Epoch 3 Loss 0.5554 Accuracy 0.0719\n","Time taken for 1 epoch: 140.4090383052826 secs\n","\n","Epoch 4 Batch 0 Loss 0.4281 Accuracy 0.0810\n","Saving checkpoint for epoch 4 at /content/drive/My Drive/machine translation/checkpoints/train/ckpt-4\n","Epoch 4 Loss 0.4454 Accuracy 0.0817\n","Time taken for 1 epoch: 140.6710135936737 secs\n","\n","Epoch 5 Batch 0 Loss 0.3438 Accuracy 0.0883\n","Saving checkpoint for epoch 5 at /content/drive/My Drive/machine translation/checkpoints/train/ckpt-5\n","Epoch 5 Loss 0.3601 Accuracy 0.0898\n","Time taken for 1 epoch: 140.35302448272705 secs\n","\n","Epoch 6 Batch 0 Loss 0.2760 Accuracy 0.0998\n","Saving checkpoint for epoch 6 at /content/drive/My Drive/machine translation/checkpoints/train/ckpt-6\n","Epoch 6 Loss 0.2955 Accuracy 0.0965\n","Time taken for 1 epoch: 141.00823879241943 secs\n","\n","Epoch 7 Batch 0 Loss 0.1907 Accuracy 0.1043\n","Saving checkpoint for epoch 7 at /content/drive/My Drive/machine translation/checkpoints/train/ckpt-7\n","Epoch 7 Loss 0.2498 Accuracy 0.1016\n","Time taken for 1 epoch: 140.5631844997406 secs\n","\n","Epoch 8 Batch 0 Loss 0.1990 Accuracy 0.1132\n","Saving checkpoint for epoch 8 at /content/drive/My Drive/machine translation/checkpoints/train/ckpt-8\n","Epoch 8 Loss 0.2223 Accuracy 0.1044\n","Time taken for 1 epoch: 140.60002374649048 secs\n","\n","Epoch 9 Batch 0 Loss 0.1856 Accuracy 0.1094\n","Saving checkpoint for epoch 9 at /content/drive/My Drive/machine translation/checkpoints/train/ckpt-9\n","Epoch 9 Loss 0.2060 Accuracy 0.1059\n","Time taken for 1 epoch: 141.07354140281677 secs\n","\n","Epoch 10 Batch 0 Loss 0.1508 Accuracy 0.1122\n","Saving checkpoint for epoch 10 at /content/drive/My Drive/machine translation/checkpoints/train/ckpt-10\n","Epoch 10 Loss 0.1813 Accuracy 0.1094\n","Time taken for 1 epoch: 140.3887906074524 secs\n","\n","Epoch 11 Batch 0 Loss 0.1376 Accuracy 0.1177\n","Saving checkpoint for epoch 11 at /content/drive/My Drive/machine translation/checkpoints/train/ckpt-11\n","Epoch 11 Loss 0.1574 Accuracy 0.1136\n","Time taken for 1 epoch: 140.28636288642883 secs\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VoCcx67_sEZd","colab_type":"text"},"source":["Evaluate\n","\n","\n","The following steps are used for evaluation:\n","\n","Encode the input sentence using the english tokenizer (tokenizer_en). Moreover, add the start and end token so the input is equivalent to what the model is trained with. This is the encoder input.\n","\n","The decoder input is the start token == tokenizer_pl.vocab_size.\n","\n","Calculate the padding masks and the look ahead masks.\n","\n","The decoder then outputs the predictions by looking at the encoder output and its own output (self-attention).\n","\n","Select the last word and calculate the argmax of that.\n","\n","Concatentate the predicted word to the decoder input as pass it to the decoder.\n","\n","In this approach, the decoder predicts the next word based on the previous words it predicted."]},{"cell_type":"code","metadata":{"id":"Ho1Mtl_QrN7H","colab_type":"code","colab":{}},"source":["def encode_en(en):\n","    tokens_en = tokenizer_en.tokenize(en)\n","    lang1 = tokenizer_en.convert_tokens_to_ids(['[CLS]'] + tokens_en + ['[SEP]'])\n","    return lang1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7uciLiwFsgp8","colab_type":"code","colab":{}},"source":["def evaluate(transformer, inp_sentence):\n","    # normalize input sentence\n","    inp_sentence = encode_en(inp_sentence)\n","    encoder_input = tf.expand_dims(inp_sentence, 0)\n","\n","    # as the target is english, the first word to the transformer should be the\n","    # english start token.\n","    decoder_input = [tokenizer_pl.vocab_size]\n","    output = tf.expand_dims(decoder_input, 0)\n","\n","    for i in range(MAX_SEQ_LENGTH):\n","        combined_mask, dec_padding_mask = create_masks(\n","            encoder_input, output)\n","\n","        # predictions.shape == (batch_size, seq_len, vocab_size)\n","        predictions, attention_weights = transformer(encoder_input,\n","                                                     output,\n","                                                     False,\n","                                                     combined_mask,\n","                                                     dec_padding_mask)\n","\n","        # select the last word from the seq_len dimension\n","        predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n","\n","        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n","\n","        # return the result if the predicted_id is equal to the end token\n","        if tf.equal(predicted_id, tokenizer_pl.vocab_size + 1):\n","            return tf.squeeze(output, axis=0), attention_weights\n","\n","        # concatentate the predicted_id to the output which is given to the decoder\n","        # as its input.\n","        output = tf.concat([output, predicted_id], axis=-1)\n","\n","    return tf.squeeze(output, axis=0), attention_weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fo4JTTl9sxge","colab_type":"code","colab":{}},"source":["def translate(transformer, sentence):\n","    result, attention_weights = evaluate(transformer, sentence)\n","\n","    predicted_sentence = tokenizer_pl.decode([i for i in result\n","                                              if i < tokenizer_pl.vocab_size])\n","\n","    print('Input: {}'.format(sentence))\n","    print('Predicted translation: {}'.format(predicted_sentence))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KFZEmFHF6S5j","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1600319884541,"user_tz":-330,"elapsed":3365,"user":{"displayName":"vivek gohel","photoUrl":"","userId":"08799214395694087015"}},"outputId":"67affd1c-ee83-478b-af4c-c67a7d3e39c2"},"source":["translate(transformer, 'she heard him cry.')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input: she heard him cry.\n","Predicted translation: Usłyszała jak płacze.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GWWImMb6TwRG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1600319913459,"user_tz":-330,"elapsed":4367,"user":{"displayName":"vivek gohel","photoUrl":"","userId":"08799214395694087015"}},"outputId":"0ec533c6-c54b-48d4-ff11-9db7d7bc6002"},"source":["translate(transformer, 'tom intervened.')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input: tom intervened.\n","Predicted translation: Tom właśnie Tom właśnie mówił się Tom.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Mtgoum0MTwOM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1600319946838,"user_tz":-330,"elapsed":2888,"user":{"displayName":"vivek gohel","photoUrl":"","userId":"08799214395694087015"}},"outputId":"a0df3d32-5d14-42f9-f2c3-5f040475fb2e"},"source":["translate(transformer, 'tom looks happy.')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input: tom looks happy.\n","Predicted translation: Tom wygląda na zadowolonego.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2gDd1CzqTwMR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1600319965083,"user_tz":-330,"elapsed":4267,"user":{"displayName":"vivek gohel","photoUrl":"","userId":"08799214395694087015"}},"outputId":"591ceebd-578d-44fe-ad70-f016b0807245"},"source":["translate(transformer, 'tom hid under the table.')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input: tom hid under the table.\n","Predicted translation: Tom chowe się pod stołem pod stole.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FvCFC8OzTwJq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1600320059871,"user_tz":-330,"elapsed":3139,"user":{"displayName":"vivek gohel","photoUrl":"","userId":"08799214395694087015"}},"outputId":"6ffbd558-2960-4413-f897-279e9115880e"},"source":["translate(transformer, 'please pass my laptop.')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input: please pass my laptop.\n","Predicted translation: Proszę mi swoją przejłać.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OtzwxbEvWI2c","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1600320021576,"user_tz":-330,"elapsed":2807,"user":{"displayName":"vivek gohel","photoUrl":"","userId":"08799214395694087015"}},"outputId":"d69a7bcd-76ba-4afb-cc7a-cd1f69c76ea0"},"source":["translate(transformer, 'i love you.')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input: i love you.\n","Predicted translation: Kocham w tobie.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kh4zGnL3Y3k4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1600320079963,"user_tz":-330,"elapsed":3427,"user":{"displayName":"vivek gohel","photoUrl":"","userId":"08799214395694087015"}},"outputId":"5e563a42-0bc4-4a81-81aa-c856752f38f6"},"source":["translate(transformer, 'beautifull')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input: beautifull\n","Predicted translation: Takcie się piękna.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UyEn97UjtdHC","colab_type":"text"},"source":["Save weights"]},{"cell_type":"code","metadata":{"id":"6NTV3ZZ7sxQ4","colab_type":"code","colab":{}},"source":["transformer.save_weights('/content/drive/My Drive/machine translation/bert_nmt_ckpt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7L_1hW-CsxPR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600320155141,"user_tz":-330,"elapsed":4391,"user":{"displayName":"vivek gohel","photoUrl":"","userId":"08799214395694087015"}},"outputId":"bbb01515-3978-4b8d-c8e6-9587bc8d8048"},"source":["new_transformer = Transformer(config=config,\n","                          target_vocab_size=target_vocab_size,\n","                          bert_config_file=bert_config_file)\n","  \n","fn_out, _ = new_transformer(inp, tar_inp, \n","                        True,\n","                        look_ahead_mask=None,\n","                        dec_padding_mask=None)\n","new_transformer.load_weights('/content/drive/My Drive/machine translation/bert_nmt_ckpt')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fb057b27a90>"]},"metadata":{"tags":[]},"execution_count":69}]},{"cell_type":"code","metadata":{"id":"hZvf_CrJt-ug","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1600320182857,"user_tz":-330,"elapsed":2285,"user":{"displayName":"vivek gohel","photoUrl":"","userId":"08799214395694087015"}},"outputId":"509dd323-fb45-4b34-861a-5b6807177fc9"},"source":["translate(transformer, 'go.')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input: go.\n","Predicted translation: Idź iść.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sYTsjLkNkzpk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1600321193791,"user_tz":-330,"elapsed":3940,"user":{"displayName":"vivek gohel","photoUrl":"","userId":"08799214395694087015"}},"outputId":"87313326-b08a-4853-fa0a-b488687f5ffd"},"source":["translate(transformer, 'take a walk every day.')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input: take a walk every day.\n","Predicted translation: Idź na spacer każdego dnia .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rEPdjpE1k-LY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1600321233172,"user_tz":-330,"elapsed":3624,"user":{"displayName":"vivek gohel","photoUrl":"","userId":"08799214395694087015"}},"outputId":"08296d8c-68c2-4fbf-c288-458e33cc857a"},"source":["translate(transformer, 'i still dont like you.')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input: i still dont like you.\n","Predicted translation: Nadal Cię nie lubię.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"36nux6p_lJv_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1600321514126,"user_tz":-330,"elapsed":14363,"user":{"displayName":"vivek gohel","photoUrl":"","userId":"08799214395694087015"}},"outputId":"9225fe4a-ae19-41cd-9f14-5b0146520f3e"},"source":["translate(transformer, ' i have just washed all the dishes.')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input:  i have just washed all the dishes.\n","Predicted translation: Właśnie umyć wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie wszystkie \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x2fQHUHnhGsc","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}